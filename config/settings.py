"""
Automated Slot Studio - Configuration & LLM Routing

PHASE 2: HYBRID LLM WIRING (PRODUCTION)
========================================
- Real litellm-compatible model strings (CrewAI uses litellm under the hood)
- Per-agent temperature + max_tokens via LLM config dicts
- Token budget tracking + cost estimation
- Swap models by changing ONE string per agent
"""

import os
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

BASE_DIR = Path(__file__).parent.parent
OUTPUT_DIR = Path(os.getenv("OUTPUT_DIR", "./output"))


# ============================================================
# HYBRID LLM ROUTING
#
# CrewAI uses litellm → model strings MUST be litellm-compatible:
#   "openai/gpt-4o"          → OpenAI
#   "openai/gpt-4o-mini"     → OpenAI (cheap tier)
#   "azure/gpt-4o"           → Azure OpenAI
#   "anthropic/claude-sonnet-4-5-20250929" → Anthropic
#   "ollama/llama3"           → Local
#
# When GPT-5 launches, change the strings here. Nothing else changes.
# ============================================================

class LLMConfig:

    # --- Tier 1: Heavy Reasoning (accuracy-critical) ---
    # NOTE: If you have OpenAI Tier 1 (30K TPM on gpt-4o), keep only 1-2 agents on HEAVY.
    # Upgrade to Tier 2+ ($50 spent) for 450K TPM and better parallelism.
    # Override via env: LLM_HEAVY=openai/gpt-4o LLM_LIGHT=openai/gpt-4o-mini
    HEAVY = os.getenv("LLM_HEAVY", "openai/gpt-4o")

    # --- Tier 2: Lightweight (cost-sensitive, high-token) ---
    LIGHT = os.getenv("LLM_LIGHT", "openai/gpt-4o-mini")

    # --- Image Generation ---
    IMAGE_MODEL = "dall-e-3"

    # --- Per-Agent Routing ---
    # Optimized for 30K TPM on gpt-4o: only designer + mathematician on HEAVY.
    # All others on gpt-4o-mini to avoid rate limits.
    AGENTS = {
        "lead_producer":      {"model": LIGHT, "temperature": 0.3, "max_tokens": 16384},
        "market_analyst":     {"model": LIGHT, "temperature": 0.4, "max_tokens": 16384},
        "game_designer":      {"model": HEAVY, "temperature": 0.6, "max_tokens": 16384},
        "mathematician":      {"model": HEAVY, "temperature": 0.1, "max_tokens": 16384},
        "art_director":       {"model": LIGHT, "temperature": 0.7, "max_tokens": 16384},
        "compliance_officer": {"model": LIGHT, "temperature": 0.1, "max_tokens": 16384},
    }

    # --- Token Budgets (soft limit per agent per run) ---
    TOKEN_BUDGETS = {
        "lead_producer": 75_000,
        "market_analyst": 250_000,
        "game_designer": 150_000,
        "mathematician": 125_000,
        "art_director": 200_000,
        "compliance_officer": 100_000,
    }

    # --- Cost Rates (USD per 1M tokens) — update when pricing changes ---
    COST_INPUT = {"openai/gpt-4o": 2.50, "openai/gpt-4o-mini": 0.15}
    COST_OUTPUT = {"openai/gpt-4o": 10.00, "openai/gpt-4o-mini": 0.60}
    COST_IMAGE = {"1024x1024": 0.04, "1792x1024": 0.08}
    COST_AUDIO_SFX = 0.01  # Estimated per ElevenLabs sound effect generation

    @classmethod
    def get_llm(cls, agent_key: str) -> str:
        """Return the litellm model string for CrewAI's `llm` param."""
        return cls.AGENTS.get(agent_key, {}).get("model", cls.LIGHT)

    @classmethod
    def get_config(cls, agent_key: str) -> dict:
        """Return full config dict for an agent."""
        return cls.AGENTS.get(agent_key, {"model": cls.LIGHT, "temperature": 0.5, "max_tokens": 16384})


# ============================================================
# Cost Tracker — one per pipeline run
# ============================================================

class CostTracker:
    def __init__(self):
        self.usage = {}
        self.images = 0
        self.image_cost = 0.0

    def log(self, agent_key: str, input_tokens: int = 0, output_tokens: int = 0):
        if agent_key not in self.usage:
            self.usage[agent_key] = {"input": 0, "output": 0, "calls": 0}
        self.usage[agent_key]["input"] += input_tokens
        self.usage[agent_key]["output"] += output_tokens
        self.usage[agent_key]["calls"] += 1
        total = self.usage[agent_key]["input"] + self.usage[agent_key]["output"]
        budget = LLMConfig.TOKEN_BUDGETS.get(agent_key, float("inf"))
        if total > budget:
            print(f"⚠️  {agent_key} token budget exceeded: {total:,}/{budget:,}")

    def log_image(self, size="1024x1024"):
        self.images += 1
        self.image_cost += LLMConfig.COST_IMAGE.get(size, 0.04)

    def total_tokens(self) -> int:
        return sum(v["input"] + v["output"] for v in self.usage.values())

    def total_cost(self) -> float:
        cost = 0.0
        for key, data in self.usage.items():
            model = LLMConfig.get_llm(key)
            cost += (data["input"] / 1e6) * LLMConfig.COST_INPUT.get(model, 5.0)
            cost += (data["output"] / 1e6) * LLMConfig.COST_OUTPUT.get(model, 15.0)
        return round(cost + self.image_cost, 4)

    def summary(self) -> dict:
        return {
            "per_agent": {
                k: {"model": LLMConfig.get_llm(k), **v, "budget": LLMConfig.TOKEN_BUDGETS.get(k)}
                for k, v in self.usage.items()
            },
            "total_tokens": self.total_tokens(),
            "total_images": self.images,
            "estimated_cost_usd": self.total_cost(),
        }


# ============================================================
# Pipeline Configuration
# ============================================================

class PipelineConfig:
    HITL_ENABLED = os.getenv("HITL_ENABLED", "true").lower() == "true"
    HITL_CHECKPOINTS = {"post_research": True, "post_design_math": True, "post_art_review": True}
    SIMULATION_SPINS = int(os.getenv("SIMULATION_SPINS", "1000000"))
    COMPETITOR_BROAD_SWEEP_LIMIT = 30
    COMPETITOR_DEEP_DIVE_LIMIT = 10
    MOOD_BOARD_VARIANTS = 4
    IMAGE_SIZES = {"mood_board": "1024x1024", "symbol": "1024x1024", "background": "1792x1024"}


# ============================================================
# RAG Configuration
# ============================================================

class RAGConfig:
    QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
    QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", "")
    COLLECTION_NAME = os.getenv("QDRANT_COLLECTION", "slot_regulations")
    EMBEDDING_MODEL = "text-embedding-3-small"
    EMBEDDING_DIM = 1536
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    TOP_K = 10
    DOCUMENT_SOURCES = {
        "gli_standards": "data/regulations/gli/",
        "ukgc_rules": "data/regulations/ukgc/",
        "mga_rules": "data/regulations/mga/",
        "ontario_rules": "data/regulations/ontario/",
        "company_games": "data/internal/past_games/",
    }


# ============================================================
# Jurisdiction Database (Static — RAG fallback)
#
# INTERNATIONAL markets + US STATE LOOPHOLE ANALYSIS
# Each US state entry includes:
#   - gambling_definition: How the state defines illegal gambling
#   - legal_avenues: Known legal pathways for game placement
#   - loophole_strategy: Specific game design tweaks to exploit
#   - risk_level: LOW / MEDIUM / HIGH / EXTREME
#   - key_statutes: Primary laws to watch
#   - enforcement_notes: How aggressively the state enforces
# ============================================================

JURISDICTION_REQUIREMENTS = {

    # ========== INTERNATIONAL ==========

    "UK": {
        "regulator": "UKGC", "min_rtp": 80.0, "max_win_cap": None,
        "certifiers": ["GLI", "BMM", "eCOGRA", "NMi"],
        "content_restrictions": [
            "No content appealing primarily to children",
            "Responsible gambling messaging required",
            "Reality check at 60-minute intervals",
            "Session time and loss limits mandatory",
        ],
        "data_privacy": "GDPR",
    },
    "Malta": {
        "regulator": "MGA", "min_rtp": 85.0, "max_win_cap": None,
        "certifiers": ["GLI", "BMM", "iTech Labs"],
        "content_restrictions": ["No offensive or discriminatory content", "RNG certification required"],
        "data_privacy": "GDPR",
    },
    "Ontario": {
        "regulator": "AGCO/iGO", "min_rtp": 85.0, "max_win_cap": None,
        "certifiers": ["GLI", "BMM", "iTech Labs", "Gaming Associates"],
        "content_restrictions": [
            "Responsible gambling tools mandatory",
            "Self-exclusion integration required",
            "No inducements to problem gambling",
        ],
        "data_privacy": "PIPEDA",
    },
    "New Jersey": {
        "regulator": "NJ DGE", "min_rtp": 83.0, "max_win_cap": None,
        "certifiers": ["GLI", "BMM"],
        "content_restrictions": [
            "Geolocation verification required",
            "Age verification mandatory",
            "Responsible gambling features required",
        ],
        "data_privacy": "State privacy laws",
    },
    "Curacao": {
        "regulator": "Curacao eGaming", "min_rtp": 75.0, "max_win_cap": None,
        "certifiers": ["GLI", "iTech Labs"],
        "content_restrictions": ["Basic responsible gambling messaging"],
        "data_privacy": "Minimal requirements",
    },

    # ========== US STATES ==========
    # NO STATIC DATA — All US state jurisdiction data lives in Qdrant.
    # Run the State Recon Pipeline to research any state:
    #   python -m flows.state_recon --state "North Carolina"
    # Results are auto-ingested into Qdrant and stay current.
}


# ============================================================
# DEPRECATED — Static loophole data removed.
# All US jurisdiction intelligence now lives in Qdrant,
# populated and refreshed by the State Recon Pipeline.
# Query via: RegulatoryRAGTool → search_regulations
# Research via: StateReconFlow → python -m flows.state_recon --state "X"
# ============================================================
